<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1">

    <script type="text/javascript" src="https://use.fontawesome.com/981e0eb420.js"></script>
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css"/>
    <link href='http://fonts.googleapis.com/css?family=Lato:300,400,700,900%7COpen+Sans:400,600' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="../../static/style.css" />




<script type="text/javascript"
   src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default">
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [["$","$"],["\\(","\\)"]]}
  });
</script>

</head>
<body>

    <div class="blog-container">
        <div class="row">
            <div class="col-sm-12">



<h2>Two Ways of Thinking about Least Squares Regression</h2>
</br></br>
<h4>Intro</h4>
There's two ways to look at least squares optimization for simple linear regression. One uses calculus and the other, linear algebra. These two ways of looking at the same thing is a lovely example of math's beauty. I want to explain the two views here, making little to no assumptions about the prior knowledge of the reader. Hopefully you'll get a sense of this thing's beauty too.

</br></br>
<h4>Machine Learning Fundamentals</h4>
Deep learning is a branch of machine learning. In order to build an understanding of deep learning, then, we need background on the basic principles of machine learning. 
</br></br>
A machine learning algorithm is one that is capable of improving automatically from experience. In most cases, ``experience" in this context means data, but how does an algorithm actually go about learning how to do things? In answering this question, it is advantageous to formalize our discussion. A popular definition of learning in the context of algorithms and code is as follows:
</br></br>
$\bf{Definition:}$ ``A computer program is said to $learn$ from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, as measured by $P$, improves with experience $E$" [1]. 
</br></br>
In other words, when a program is trying to accomplish some task, it measures its performance as it runs. A program $learns$ when its performance on this task improves over time. For example, if a computer program is learning how to play ping pong with a robotic arm, the task is $playing\ ping\ pong$, its performance is measured by its $ability\ to\ win$, and it accrues experience by $playing\ games\ of\ ping\ pong$.
</br></br> 
<h4>Linear Regression</h4>
By this point, we have assembled the needed framework to understand our first machine learning algorithm: $linear\ regression$. It is a simple example that underlines many of the fundamental ideas we will encounter. It is also a good chance to wet our toes with the kind of mathematical thinking we will encounter during our exploration of deep learning. Even if you know what linear regression is, it is valuable and refreshing to reconsider from a machine learning perspective. 
</br></br>
In the case of linear regression the task is predicting the value of a scalar $y \in \mathbb{R}$ (a number) based on a vector input $\bf{x}\in \mathbb{R}^{n+1}$ (several numbers denoted $x_0,\ x_1,\ x_2,...,\ x_n$ where $x_0 = 1$). This task can be thought of as follows: we have a bunch of observations (${\bf x}, y$). We assume the $y$'s are generated by a function $f({\bf x})=y$. We want to learn what $f$ is, so we develop an approximation of $f$ called $\hat{f}$. Note that our $\hat{f}$ will produce approximations of the $y$'s: $\hat{f}({\bf x}) = \hat{y}$. In a machine learning context, $f$ is often assumed to be a probability distribution that is generating each $y$. $\hat{f}$ maps ${\bf x}$ to $\hat{y}$ by taking a linear combination of ${\bf x}$ and its $parameters$ ${\bf w}$. This means that 
\begin{align*}
\hat{f}({\bf x}) &= \hat{y} \\
&= {\bf w}^{T} {\bf x} \\
&= \sum_{i = 0}^n w_i x_i \\
&= w_0 + w_1 x_1 + w_2 x_2 + \cdot \cdot \cdot + w_n x_n
\end{align*} 
where ${\bf w} \in \mathbb{R}^{n+1}$ is a vector of parameters. In a machine learning context, the parameters are known as $weights$. Weights control the behavior of our predictions. Each weight $w_i$ controls how much power the $i^{\mathrm{th}}$ input has in determining the output $\hat{y}$. 
</br></br>
We now have a good grasp on our task: to produce a mapping of ${\bf x}$'s to $\hat{y}$'s such that $\hat{y} = {\bf w}^{T} {\bf x}$. An example of this might be predicting the probability of a honey bee swarm given some recent weather data and hive demographics. 
</br></br>
<h4>Objective Functions</h4>
Now we need to be able to track our performance. In linear regression, it makes sense to equate performance with $error$. Good performance is a small error rate, and poor performance is a large error rate. Coming up with a performance measurement, then, is analogous to measuring the error made by our model. 
</br></br>
A first attempt at defining the error $E$ might simply be the difference between the prediction of our model and the value we are trying to predict:
\begin{align*}
E({\bf x}) &= f({\bf x}) - \hat{f}({\bf x}) \\
&= y - \hat{y}
\end{align*}
The problem with this is that if $\hat{y} > y$, then $E$ will be negative. This doesn't make sense (what does a negative error mean?), so we might redefine a new error, $E'$, that takes the absolute value of this difference
\begin{align*}
 E'({\bf x}) &= \vert f({\bf x}) - \hat{f}({\bf x})\vert \\
 &= \vert y - \hat{y} \vert
 \end{align*}
This works, but our intuition tells us that the more wrong a prediction is, the worse its error should be. This leads us to the $squared\ error$ measure, one we will use later in our discussion of neural networks:
\begin{align*}
E''({\bf x}) &= ( f({\bf x}) - \hat{f}({\bf x}))^2  \\
&= ( y - \hat{y} )^2 
\end{align*}
 Now that we have a task and a performance measurement, we need to think about what $experience$ means in the context of regression. Experience is the same thing as data. More experience is more data. The data come in two types. The first, ${\bf X}^{m +1 \times n}$, is a special matrix called the $design\ matrix$. It consists of a list of $n$ $observations$ ${\bf x}_1$, ${\bf x}_2$, ..., ${\bf x}_n$. Each observation is a single vector or data point. Observations consist of $m$ $attributes$ (1, $x_1$, $x_2$, ..., $x_m) \in {\bf x}$. In a graphical interpretation, each $x_i \in {\bf x}_k$ is a coordinate for the $i^{\mathrm{th}}$ dimension for data point $k$. 
\[
{\bf X} = \begin{bmatrix}
 {\bf x_1} & ... & {\bf x_n}
 \end{bmatrix}
=\begin{bmatrix}
1 & 1 &...&1 \\
x_{11} & x_{12} & ... & x_{1n} \\
...& ... &... & ...\\
x_{m1} & x_{m2}& ...& x_{mn}
\end{bmatrix}
\]
The second data matrix is ${\bf y}$. This is a vector of regression targets -- things we are trying to predict. 
</br></br>
We can expand our definition of error so that it takes this data into account. The result, $mean\ squared\ error$ ($MSE$), is an average of all the $E''$ values each ${\bf x}_i$:
\[ MSE = \frac{1}{n}\sum_{i = 1}^n \bigg( f({\bf x}_i) - \hat{f}({\bf x}_i)\bigg)^2 \]
Notice that the format our linear regression problem has taken is now the same as the kinds of problems machine learning algorithms try to solve. We have a bunch of stuff to be done (predict $\hat{y}$'s from all of the ${\bf x}_i$'s) and a bunch of stuff that's already done ($y_i$'s for each ${\bf x}_i$). All that remains is to show the model this data and $teach$ it how to improve its predictions.
</br></br>
<h4>Optimization</h4>
When we say $learn\ from\ data$, we mean leveraging our experience to improve performance. With regards to linear regression this means using our data (${\bf X}$ and ${\bf y}$) to find the weights ${\bf w}$ that perform the best (produce the smallest $MSE$). This process is called $optimization$. 
</br></br>
There are many ways to optimize for ${\bf w}$, each with their own interpretation. My personal favorite comes from linear algebra. To start, lets put the task at hand into matrix notation. We are trying to solve for
\begin{align*}
\hat{{\bf y}} &= {\bf X}^T {\bf w} \\
\begin{bmatrix}
\hat{y}_1 \\
\hat{y}_2 \\
\cdot\cdot\cdot\\
\hat{y}_n 
\end{bmatrix} &=
\begin{bmatrix}
1 &x_{11}&...&x_{1m}\\
...& ... &... & ...\\
1 & x_{n1}& ...& x_{nm}
\end{bmatrix}
\begin{bmatrix}
w_0 \\
w_1 \\
... \\
w_m
\end{bmatrix}
\end{align*}
so that our choice for ${\bf w}$ produces the optimal ${\bf \hat{y}}$. This can be rewritten as solving 
\begin{align*}
{\bf y} &= {\bf X}^T {\bf w} + {\bf \epsilon}\\
\begin{bmatrix}
y_1 \\
y_2 \\
\cdot\cdot\cdot\\
y_n
\end{bmatrix} &= 
\begin{bmatrix}
1 &x_{11}&...&x_{1m}\\
...& ... &... & ...\\
1 & x_{n1}& ...& x_{nm}
\end{bmatrix}
\begin{bmatrix}
w_0 \\
w_1 \\
... \\
w_m
\end{bmatrix}
+ \begin{bmatrix}
\epsilon_1 \\
\epsilon_2 \\
... \\
\epsilon_n
\end{bmatrix}
\end{align*}
where the individual $\epsilon_i$'s are the $error\ terms$ for each observation $i$:
\begin{align*}
\epsilon_i &= (y_i - \hat{y}_i)^2
\end{align*} 
Optimizing $\hat{f}$, then, becomes the task of choosing a ${\bf w}$ such that the mean of all $\epsilon_i$'s is minimized. 
</br></br>
<h4>Two Views of the Same Thing</h4>
Now for the fun stuff. Remember that each vector has a visual interpretation as a point in a coordinate system. The entire ${\bf y}$ and ${\bf \hat{y}}$ vectors are merely points in $n$-dimensional space (because $\vert {\bf y}\vert = \vert{\bf \hat{y}}\vert = n$). Each observation is a point in $m+1$ dimensional space (because each$\ {\bf x}_i \in {\bf X}$ has length $m+1$). Running data points through $\hat{f}$ is equivalent to taking a $linear\ combination$ of each ${\bf x} \in {\bf X}$ because we can only perform linear operations on each observation: we can multiply attributes by weights and sum the results. This means that the only ${\bf \hat{y}}$'s that are possible are those reachable by taking different linear combinations of our ${\bf x}$'s. All of the possibilities for ${\bf \hat{y}}$, then, create a region within our $m+1$ dimensional space. This region is known as the space $spanned$ by ${\bf X}$. 
</br></br>
The process of optimizing ${\bf w}$ now has a nice visual interpretation to it. Because ${\bf y}$ exists in $n$ dimensions and the space spanned by ${\bf X}$ exists in only $m+1$ dimensions, we need to $project$ ${\bf y}$ into this lower-dimensional world (note that we are assuming $n > (m +1)$). We do this by selecting the ${\bf w}$ that makes ${\bf \hat{y}} = {\bf X}^{T} {\bf w}$ as close as possible to ${\bf y}$!
</br></br>
<img src="figs/regression_projection.jpg" alt="Mountain View" style="width:600px;">
</br>
This shows two interpretations of linear regression. To the  $left$ is the coordinate-space interpretation of regression with 1-dimensional inputs. To the $right$ is the vector-space interpretation of regression with high dimensional inputs.
</br></br>
 By selecting a ${\bf w}$ in this way, our algorithm is learning how to improve (produce better predictions that minimize error) by using experience, or data. 
</br></br>
 This concludes our discussion of linear regression. The core idea that is at the heart of this algorithm, improving with experience, is one that is central to deep learning and indeed all of machine learning. Plus, I think those two ways of looking at least squares optimization (partial derivatives and projection) are really quite lovely.

<h4>References</h4>
<ol>
<li>Mitchell, Tom M. $Machine\ Learning.$ New York: McGraw-Hill, 1997. Print.
</ol>


</br>
</br></br></br>



</body>
</html>

