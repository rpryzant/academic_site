<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Reid Pryzant</title>


    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
    <script type="text/javascript" src="https://use.fontawesome.com/981e0eb420.js"></script>
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css"/>
    <link href='http://fonts.googleapis.com/css?family=Lato:300,400,700,900%7COpen+Sans:400,600' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="../../static/style.css" />
</head>


<body>

    <div class="blog-container">
        <div class="row">
            <div class="col-sm-12">
              <br/><br/>
	      <h1>Reid Pryzant's Blog
                    <small>
		      <span> <a href="../../index.html">home</a>
                        </span>
                    </small>
                </h1>
            </div>
        </div>
        <hr/>


<h2>Proximal Gradient Descent</h2>
<h3 style="text-align:center"> 2015</h3>

<h4>What is this this thing??</h4>

The python file in this project is some rough pseudocode for proximal gradient descent. Below is a hastily written intuitive explanation of the method.
</br></br></br>

<h4>Why we need Proximal Gradient Descent</h4>
Proximal gradient descent falls into a broader category of methods to fit statistical models to data. This fitting usually requires some sort of optimization. In a perfect world the function we are trying to optimize is convex, differentiable, and unconstrained. This means all we would need to do is basic gradient descent.
</br></br>
In many real world applications, though, we don't have this luxury. A great example is the class of models with L1 regularization schemes like Lasso regression. This regularization method is an effective promoter of sparsity but it results in a loss function that is non-differentiable (aka it has kinks). This introduces a whole bunch of problems. For example, we might not always be able to compute a gradient to descent. Proximal gradient descent is a way of getting around this.
</br></br></br>

<h4>Some Definitions</h4>
The method makes use of two mathematical tools you may not have heard of already. Lets talk about them.
<ul>
</br></br>

<li><b>Sub-Gradients</b>
</br></br>
sub-gradients are a generalization of the concept of the gradient which can be applied to non-differentiable functions.
First, let's visualize what the gradient of a convex, differentiable function looks like. These functions look like the mouth of a smiley face. The gradient of such a function is like a line which touches the curve at only one point. Note that if this is going to be true, the entire rest of the function is held above this line. Ok. That was painless.
</br></br>
Let's go on to convex non-differentiable functions. These are like smiley mouths with at least one kink, and they have sub-gradients instead of gradients. Sub-gradients are sets of vectors. Each vector in this set is kind of like a gradient. They touch at only one point and the entire function is held above them. This means that the only element in the sub-gradient IS the gradient at all the smooth, curvey parts of our function. At the kinks, though, the sub-gradient is the set of all lines which are below the function.
</br></br>

<img class="" src="../img/1.1.graph.png" alt="graph" class="blogimg">


</br></br></li>

<li><b>Proximal Operators</b>
</br></br>
The proximal operator takes a point in a space (x) and returns another point (x'). It is parameterized by a function (f) and a scalar (g).
x' is chosen because it both minimizes f and is close to x (in the L2 sense). The tradeoff between minimizing f and staying close to x is determined by g.
</br></br>
<img style="text-align:center;" src="../img/1.2.equation.png" alt="equation" class="blogimg">
Formula for proximal operator courtisy of Wikipedia. Yeah yeah the notation is not what I used but I know you love formulas to take it or leave it.
</br></br>
</li>

<li><b>Optimality Conditions</b>
</br></br>
At the minimum of a differentiable function the gradient must be zero. This is because if it wasn't zero, we could just move in the direction of -gradient(f).
For non-differentiable convex functions, this optimality contidion isn't helpful because the minimum might be a kink where you can't differentiate.
Good thing we have our old friend the sub-gradient! Even if the the minimum point (x) is a kink, 0 must be in the set of sub gradient's at x.
</li></br></br></br>
<h4>Proximal descent</h4>

Basically it works like this:
</br></br>
<ul>
  <li>Break f into two parts: g (the differentiable part) and h (the non-differentiable part).</li>
  <li>Take a step along the gradient of g to minimize that part of the function.</li>
  <li>Use the proximal operator to take another step that reduces h while staying close to the point selected by (2)</li>
  <li>Repeat (2) and (3) until the optimality condition is met.</li>
</uk>
</br></br></br>
<h4>Code</h4>
See some pseudocode for proximal gradient descent <a href="https://github.com/rpryzant/code-doodles/blob/master/linear_algebra/proximal_gradient_descent/proximal_descent.py" target="_blank">here</a>.

</br></br></br>
TODO intuitive derivation of optimality condition, proximal descent step

</div>
<hr/>

</body>
    <div class="footer">
            <a href="#">Top</a> &nbsp;&bull;&nbsp
            <a href="../../index.html">Home</a>
        </div>

</html>



